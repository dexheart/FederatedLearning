{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0824dd8e-433f-463d-bb9e-74746cc59bc1",
   "metadata": {},
   "source": [
    "# Simlação de Federated Learning Utilizando Framework do TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b6b5f-92f9-4b86-8542-55917e268dd2",
   "metadata": {},
   "source": [
    "## Declaração das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27fab1d4-584e-4261-b3ec-fc6384b67d94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:44:44.443651Z",
     "iopub.status.busy": "2022-10-09T13:44:44.443031Z",
     "iopub.status.idle": "2022-10-09T13:44:46.820885Z",
     "shell.execute_reply": "2022-10-09T13:44:46.819414Z",
     "shell.execute_reply.started": "2022-10-09T13:44:44.443493Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-09 10:44:45.428247: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tiago.linhares/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-10-09 10:44:45.428276: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import expand_dims\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Input, Lambda\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "# Variável para verificar o status de cada cliente.\n",
    "debug = 0\n",
    "\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ab979-f614-4673-bd17-08b1b4541e6b",
   "metadata": {},
   "source": [
    "## Declaração de Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ef1781a-7155-4c60-a693-7cd2dcbab2b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:44:46.822515Z",
     "iopub.status.busy": "2022-10-09T13:44:46.822344Z",
     "iopub.status.idle": "2022-10-09T13:44:46.838034Z",
     "shell.execute_reply": "2022-10-09T13:44:46.837222Z",
     "shell.execute_reply.started": "2022-10-09T13:44:46.822495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Função para carregar as Imagens.\n",
    "# As imagens devem estar em diretórios diferentes.\n",
    "def load(paths, verbose=-1):\n",
    "\n",
    "    data = list()\n",
    "    labels = list()\n",
    "    # loop over the input images\n",
    "    for (i, imgpath) in enumerate(paths):\n",
    "        # Carrega a imagem e extrai a classe do rótulo       \n",
    "        im_gray = cv2.imread(imgpath , cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.array(im_gray).flatten() # cv2.imread(imgpath) \n",
    "        # print(image.shape)\n",
    "        label = imgpath.split(os.path.sep)[-2]\n",
    "        # scale the image to [0, 1] and add to list\n",
    "        data.append(image/255)\n",
    "        labels.append(label)\n",
    "        # Mostra atualização de leituras das imagens através de uma verbose\n",
    "        if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(paths)))\n",
    "    # Retorna uma tupla com os dados e os rótulos.\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "# Função que define os clientes/membros do aprendizado federado\n",
    "# Esta função retorna um dicionário com as chaves dos respectivos clientes\n",
    "# Além do valor dos fragmentos de dados (Uma tupla contendo uma lista de imagens com rótulos)\n",
    "def create_clients(image_list, label_list, num_clients=100, initial='clients'):\n",
    "    \n",
    "\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "    #randomize the data\n",
    "    data = list(zip(image_list, label_list))\n",
    "    random.shuffle(data)  \n",
    "\n",
    "\n",
    "    # Divive um parcela dos dados para cada cliente\n",
    "    size = len(data)//num_clients\n",
    "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    # número de clientes deve ser o mesmo número de parcelas dos dados\n",
    "    assert(len(shards) == len(client_names))\n",
    "    \n",
    "    # Retorna um dicionário de cada cliente contendo uma parte de dados\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))} \n",
    "\n",
    "\n",
    "# Recebe o fragmento de dados do cliente e transforma em um objeto\n",
    "def batch_data(data_shard, bs=32):\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)\n",
    "\n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    \n",
    "    \n",
    "    if debug:\n",
    "        print('global_count', global_count, 'local_count', local_count, 'bs', bs)\n",
    "    \n",
    "    return local_count/global_count\n",
    "\n",
    "# Função para dimensionar os pesos de um modelo\n",
    "def scale_model_weights(weight, scalar):\n",
    "\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "# Retorna a soma dos pesos escalados. \n",
    "# É equivalente à média escalonada dos pesos\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "# Função que realiza o teste do modelo após o treinamento.\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    #logits = model.predict(X_test, batch_size=100)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d84f905-5513-4083-86d5-adba6548c85a",
   "metadata": {},
   "source": [
    "## Declaração de Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f721ccbf-08f6-4028-b0c5-ba05a7c779c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:44:46.839754Z",
     "iopub.status.busy": "2022-10-09T13:44:46.839591Z",
     "iopub.status.idle": "2022-10-09T13:44:46.966675Z",
     "shell.execute_reply": "2022-10-09T13:44:46.965131Z",
     "shell.execute_reply.started": "2022-10-09T13:44:46.839736Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    # MLP \n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(200, input_shape=(shape,)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model\n",
    "    \n",
    "    # CNN\n",
    "#     def build(shape, classes):\n",
    "#         model = Sequential()\n",
    "#         model.add(Input(shape=(shape[0], shape[1], shape[2])))\n",
    "#         #model.add(Lambda(lambda x: expand_dims(x, axis=-1)))\n",
    "#         model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(MaxPooling2D())\n",
    "#         model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(MaxPooling2D())\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(MaxPooling2D())\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\"))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(MaxPooling2D())\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(32))\n",
    "#         model.add(Dense(classes))\n",
    "#         model.add(Activation(\"softmax\"))\n",
    "#         return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e0ed0-8fc0-4829-9791-ec028dc5502a",
   "metadata": {},
   "source": [
    "## Diretório dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a7a3eb-5e7a-43b6-a6fa-799a268991fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:44:46.969416Z",
     "iopub.status.busy": "2022-10-09T13:44:46.968908Z",
     "iopub.status.idle": "2022-10-09T13:46:03.848310Z",
     "shell.execute_reply": "2022-10-09T13:46:03.846971Z",
     "shell.execute_reply.started": "2022-10-09T13:44:46.969338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 10000/42000\n",
      "[INFO] processed 20000/42000\n",
      "[INFO] processed 30000/42000\n",
      "[INFO] processed 40000/42000\n"
     ]
    }
   ],
   "source": [
    "# Diretório padrão do mnist no lasid\n",
    "img_path = '/data/dataset/mnist/trainingSet/trainingSet'\n",
    "\n",
    "# Obtém uma lista contendo os múltiplos caminhos de cada diretório\n",
    "# No caso do mnist são 8 diretórios\n",
    "image_paths = list(paths.list_images(img_path))\n",
    "\n",
    "# Aplica a função de carregar os dados\n",
    "image_list, label_list = load(image_paths, verbose=10000)\n",
    "\n",
    "# Binariza os rótulos\n",
    "lb = LabelBinarizer()\n",
    "label_list = lb.fit_transform(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a6e294-85c3-41d9-b135-87bd7b10f559",
   "metadata": {},
   "source": [
    "## Realiza a divisão de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57159a50-07b7-4153-91ff-cfe4df72d6d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:46:03.850495Z",
     "iopub.status.busy": "2022-10-09T13:46:03.850074Z",
     "iopub.status.idle": "2022-10-09T13:46:03.871916Z",
     "shell.execute_reply": "2022-10-09T13:46:03.870712Z",
     "shell.execute_reply.started": "2022-10-09T13:46:03.850471Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_list, \n",
    "                                                    label_list, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7dad01a-0846-4569-8969-a5f8f219ca0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:46:03.873717Z",
     "iopub.status.busy": "2022-10-09T13:46:03.873400Z",
     "iopub.status.idle": "2022-10-09T13:46:03.963387Z",
     "shell.execute_reply": "2022-10-09T13:46:03.962588Z",
     "shell.execute_reply.started": "2022-10-09T13:46:03.873697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 4200, 37800, 4200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36543308-5e1f-4153-8867-613f5888b61a",
   "metadata": {},
   "source": [
    "## Realiza Criação dos Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3b0ef5-60d3-46fa-b5c6-ce3d92fc4f9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:46:03.964504Z",
     "iopub.status.busy": "2022-10-09T13:46:03.964323Z",
     "iopub.status.idle": "2022-10-09T13:46:04.084388Z",
     "shell.execute_reply": "2022-10-09T13:46:04.082867Z",
     "shell.execute_reply.started": "2022-10-09T13:46:03.964482Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utiliza a função declarada anteriormente para criar novos clientes\n",
    "clients = create_clients(X_train, y_train, num_clients=100, initial='client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58dda195-97c9-4ef3-9d72-7091b55b38c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:46:04.085808Z",
     "iopub.status.busy": "2022-10-09T13:46:04.085623Z",
     "iopub.status.idle": "2022-10-09T13:46:04.163980Z",
     "shell.execute_reply": "2022-10-09T13:46:04.162421Z",
     "shell.execute_reply.started": "2022-10-09T13:46:04.085788Z"
    }
   },
   "outputs": [],
   "source": [
    "# client_names = ['{}_{}'.format('client', i+1) for i in range(100)]\n",
    "# s = clients['client_1'][0][1]*0\n",
    "# for c in client_names:\n",
    "#     sum = clients[c][0][1]\n",
    "#     for i in range(1,378):\n",
    "#         sum = sum + clients[c][i][1]\n",
    "        \n",
    "#     s = s + sum/378\n",
    "# s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aadf6ac-53c5-4a74-9652-eff08c444a4a",
   "metadata": {},
   "source": [
    "## Processa e agrupa os dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "605e5424-5170-44e0-a67f-0c4c396dfaa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:46:04.166775Z",
     "iopub.status.busy": "2022-10-09T13:46:04.166210Z",
     "iopub.status.idle": "2022-10-09T13:46:07.226720Z",
     "shell.execute_reply": "2022-10-09T13:46:07.225204Z",
     "shell.execute_reply.started": "2022-10-09T13:46:04.166716Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-09 10:46:04.263095: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tiago.linhares/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-10-09 10:46:04.263142: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-09 10:46:04.263164: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lasid40): /proc/driver/nvidia/version does not exist\n",
      "2022-10-09 10:46:04.263649: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "# Processa e agrupa os dados de teste\n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2cd210-f091-43aa-aac7-1bf07f6bde6e",
   "metadata": {},
   "source": [
    "## Definição de Algumas Configurações do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2fa60c4-61ef-4911-8753-2cb9da4fea1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:46:07.228301Z",
     "iopub.status.busy": "2022-10-09T13:46:07.227942Z",
     "iopub.status.idle": "2022-10-09T13:46:07.235297Z",
     "shell.execute_reply": "2022-10-09T13:46:07.234453Z",
     "shell.execute_reply.started": "2022-10-09T13:46:07.228279Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate => Taxa de aprendizagem (O quanto o modelo demora para convergir)\n",
    "lr = 0.01\n",
    "\n",
    "# Número de etapas de atualização do modelo global\n",
    "comms_round = 300\n",
    "\n",
    "# Tipo de perda\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "# Métrica de avaliação do modelo\n",
    "metrics = ['accuracy']\n",
    "\n",
    "optimizer = SGD(lr=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.9\n",
    "               )         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80335df9-e17f-4717-8bb1-be43cfc36941",
   "metadata": {},
   "source": [
    "## Inicializa o Modelo Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2bfee74-6300-4dff-b484-6b382f6f5c49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:46:07.236201Z",
     "iopub.status.busy": "2022-10-09T13:46:07.236049Z",
     "iopub.status.idle": "2022-10-09T13:46:07.362954Z",
     "shell.execute_reply": "2022-10-09T13:46:07.361430Z",
     "shell.execute_reply.started": "2022-10-09T13:46:07.236183Z"
    }
   },
   "outputs": [],
   "source": [
    "#(28, 28, 3)  # 1024 <- CIFAR-10    # 784 # para MNIST\n",
    "build_shape = 784\n",
    "\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(build_shape, 10) \n",
    "global_acc_list = []\n",
    "global_loss_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f8fb84-1824-4fc8-97ca-ac6c7f55b8eb",
   "metadata": {},
   "source": [
    "## Loop de execução principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047b750c-da5e-4b94-b9c2-5fc68d9ef19c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T13:46:07.366341Z",
     "iopub.status.busy": "2022-10-09T13:46:07.366096Z",
     "iopub.status.idle": "2022-10-09T14:09:23.591646Z",
     "shell.execute_reply": "2022-10-09T14:09:23.590886Z",
     "shell.execute_reply.started": "2022-10-09T13:46:07.366313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 0 | global_acc: 49.024% | global_loss: 2.2648963928222656\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 1 | global_acc: 64.857% | global_loss: 2.2125556468963623\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 2 | global_acc: 69.595% | global_loss: 2.125474691390991\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 3 | global_acc: 74.286% | global_loss: 2.036379098892212\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 4 | global_acc: 77.905% | global_loss: 1.9575155973434448\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 5 | global_acc: 79.738% | global_loss: 1.8952754735946655\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 6 | global_acc: 81.667% | global_loss: 1.8520911931991577\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 7 | global_acc: 83.667% | global_loss: 1.8144118785858154\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 8 | global_acc: 84.929% | global_loss: 1.7890607118606567\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 9 | global_acc: 85.143% | global_loss: 1.7647126913070679\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 10 | global_acc: 85.619% | global_loss: 1.7475064992904663\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 11 | global_acc: 85.810% | global_loss: 1.733608365058899\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 12 | global_acc: 86.952% | global_loss: 1.7192515134811401\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 13 | global_acc: 87.905% | global_loss: 1.7096103429794312\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 14 | global_acc: 87.833% | global_loss: 1.7008790969848633\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 15 | global_acc: 88.190% | global_loss: 1.6904453039169312\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 16 | global_acc: 88.405% | global_loss: 1.6839951276779175\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 17 | global_acc: 88.833% | global_loss: 1.6770857572555542\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 18 | global_acc: 88.667% | global_loss: 1.6722393035888672\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 19 | global_acc: 88.833% | global_loss: 1.6675124168395996\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 20 | global_acc: 89.167% | global_loss: 1.6612054109573364\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 21 | global_acc: 89.429% | global_loss: 1.6585707664489746\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 22 | global_acc: 89.310% | global_loss: 1.6521587371826172\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 23 | global_acc: 89.738% | global_loss: 1.649345874786377\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 24 | global_acc: 89.976% | global_loss: 1.650804877281189\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 25 | global_acc: 90.071% | global_loss: 1.6434333324432373\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 26 | global_acc: 90.000% | global_loss: 1.641238808631897\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 27 | global_acc: 90.333% | global_loss: 1.6379668712615967\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 28 | global_acc: 90.429% | global_loss: 1.6347907781600952\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 29 | global_acc: 90.310% | global_loss: 1.6324573755264282\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 30 | global_acc: 90.452% | global_loss: 1.630511999130249\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 31 | global_acc: 90.548% | global_loss: 1.628465175628662\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 32 | global_acc: 90.381% | global_loss: 1.62576425075531\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 33 | global_acc: 90.667% | global_loss: 1.6240798234939575\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 34 | global_acc: 90.619% | global_loss: 1.6231961250305176\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 35 | global_acc: 90.857% | global_loss: 1.6210092306137085\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 36 | global_acc: 90.476% | global_loss: 1.6200608015060425\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 37 | global_acc: 91.143% | global_loss: 1.6193146705627441\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 38 | global_acc: 90.690% | global_loss: 1.6181464195251465\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 39 | global_acc: 91.095% | global_loss: 1.6161190271377563\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 40 | global_acc: 90.976% | global_loss: 1.6140953302383423\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 41 | global_acc: 91.381% | global_loss: 1.6138153076171875\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 42 | global_acc: 91.357% | global_loss: 1.6113399267196655\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 43 | global_acc: 91.357% | global_loss: 1.6121056079864502\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 44 | global_acc: 91.381% | global_loss: 1.609846830368042\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 45 | global_acc: 91.476% | global_loss: 1.6102356910705566\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 46 | global_acc: 91.190% | global_loss: 1.6083790063858032\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 47 | global_acc: 91.333% | global_loss: 1.6079494953155518\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 48 | global_acc: 91.738% | global_loss: 1.6050654649734497\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 49 | global_acc: 91.524% | global_loss: 1.6043224334716797\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 50 | global_acc: 91.857% | global_loss: 1.6015113592147827\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 51 | global_acc: 91.762% | global_loss: 1.6013578176498413\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 52 | global_acc: 91.714% | global_loss: 1.5998955965042114\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 53 | global_acc: 91.952% | global_loss: 1.5992954969406128\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 54 | global_acc: 91.857% | global_loss: 1.5991417169570923\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 55 | global_acc: 91.929% | global_loss: 1.5985107421875\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 56 | global_acc: 92.095% | global_loss: 1.5963367223739624\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 57 | global_acc: 91.738% | global_loss: 1.5967966318130493\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 58 | global_acc: 91.905% | global_loss: 1.5978689193725586\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 59 | global_acc: 91.881% | global_loss: 1.5953341722488403\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 60 | global_acc: 91.857% | global_loss: 1.5941956043243408\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 61 | global_acc: 92.333% | global_loss: 1.5926142930984497\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 62 | global_acc: 92.262% | global_loss: 1.5921343564987183\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 63 | global_acc: 92.119% | global_loss: 1.5942933559417725\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 64 | global_acc: 92.167% | global_loss: 1.5909783840179443\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 65 | global_acc: 91.857% | global_loss: 1.5923402309417725\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 66 | global_acc: 92.238% | global_loss: 1.5904622077941895\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 67 | global_acc: 92.333% | global_loss: 1.5887776613235474\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 68 | global_acc: 92.405% | global_loss: 1.5883570909500122\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 69 | global_acc: 92.333% | global_loss: 1.5871214866638184\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 70 | global_acc: 92.238% | global_loss: 1.5903562307357788\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 71 | global_acc: 92.381% | global_loss: 1.5867741107940674\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 72 | global_acc: 92.524% | global_loss: 1.585225224494934\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 73 | global_acc: 92.429% | global_loss: 1.584609866142273\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 74 | global_acc: 92.595% | global_loss: 1.583582878112793\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 75 | global_acc: 92.667% | global_loss: 1.583333134651184\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 76 | global_acc: 92.571% | global_loss: 1.584065556526184\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 77 | global_acc: 92.500% | global_loss: 1.582748532295227\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 78 | global_acc: 92.548% | global_loss: 1.5840973854064941\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 79 | global_acc: 92.500% | global_loss: 1.5827226638793945\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 80 | global_acc: 92.762% | global_loss: 1.5816736221313477\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 81 | global_acc: 92.857% | global_loss: 1.5820525884628296\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 82 | global_acc: 92.881% | global_loss: 1.5808937549591064\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 83 | global_acc: 92.786% | global_loss: 1.5804712772369385\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 84 | global_acc: 92.857% | global_loss: 1.5804235935211182\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 85 | global_acc: 92.976% | global_loss: 1.5797961950302124\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 86 | global_acc: 93.000% | global_loss: 1.5790271759033203\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 87 | global_acc: 92.976% | global_loss: 1.5787392854690552\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 88 | global_acc: 92.905% | global_loss: 1.5783133506774902\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 89 | global_acc: 93.095% | global_loss: 1.5781210660934448\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 90 | global_acc: 92.952% | global_loss: 1.5762195587158203\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 91 | global_acc: 93.119% | global_loss: 1.5771347284317017\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 92 | global_acc: 93.071% | global_loss: 1.575980544090271\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 93 | global_acc: 93.095% | global_loss: 1.575555682182312\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 94 | global_acc: 93.071% | global_loss: 1.576182246208191\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 95 | global_acc: 93.000% | global_loss: 1.5747084617614746\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 96 | global_acc: 93.119% | global_loss: 1.574639081954956\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 97 | global_acc: 93.071% | global_loss: 1.5746312141418457\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 98 | global_acc: 93.333% | global_loss: 1.5743858814239502\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 99 | global_acc: 93.190% | global_loss: 1.5733753442764282\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 100 | global_acc: 93.024% | global_loss: 1.5749260187149048\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 101 | global_acc: 93.429% | global_loss: 1.5725160837173462\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 102 | global_acc: 93.333% | global_loss: 1.5726186037063599\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 103 | global_acc: 93.357% | global_loss: 1.5714443922042847\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 104 | global_acc: 93.286% | global_loss: 1.5708991289138794\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 105 | global_acc: 93.476% | global_loss: 1.5704621076583862\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 106 | global_acc: 93.548% | global_loss: 1.5705958604812622\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 107 | global_acc: 93.476% | global_loss: 1.5704017877578735\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 108 | global_acc: 93.476% | global_loss: 1.5687711238861084\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 109 | global_acc: 93.262% | global_loss: 1.5688953399658203\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 110 | global_acc: 93.333% | global_loss: 1.569826364517212\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 111 | global_acc: 93.476% | global_loss: 1.5693931579589844\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 112 | global_acc: 93.500% | global_loss: 1.568876028060913\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 113 | global_acc: 93.548% | global_loss: 1.567754864692688\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 114 | global_acc: 93.357% | global_loss: 1.5691449642181396\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 115 | global_acc: 93.571% | global_loss: 1.567048192024231\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 116 | global_acc: 93.738% | global_loss: 1.5667638778686523\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 117 | global_acc: 93.595% | global_loss: 1.566449522972107\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 118 | global_acc: 93.476% | global_loss: 1.567348837852478\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 119 | global_acc: 93.762% | global_loss: 1.5662500858306885\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 120 | global_acc: 93.571% | global_loss: 1.566092848777771\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 121 | global_acc: 93.500% | global_loss: 1.566279411315918\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 122 | global_acc: 93.643% | global_loss: 1.5650800466537476\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 123 | global_acc: 93.667% | global_loss: 1.5646470785140991\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 124 | global_acc: 93.857% | global_loss: 1.5651127099990845\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 125 | global_acc: 93.690% | global_loss: 1.564321517944336\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 126 | global_acc: 93.786% | global_loss: 1.5632604360580444\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 127 | global_acc: 93.929% | global_loss: 1.5641285181045532\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 128 | global_acc: 93.667% | global_loss: 1.563895344734192\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 129 | global_acc: 93.905% | global_loss: 1.563057541847229\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 130 | global_acc: 93.500% | global_loss: 1.5652740001678467\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 131 | global_acc: 93.738% | global_loss: 1.5622916221618652\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 132 | global_acc: 93.952% | global_loss: 1.5625344514846802\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 133 | global_acc: 93.952% | global_loss: 1.5620087385177612\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 134 | global_acc: 93.952% | global_loss: 1.561463713645935\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 135 | global_acc: 93.786% | global_loss: 1.5616507530212402\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 136 | global_acc: 93.976% | global_loss: 1.562798261642456\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 137 | global_acc: 93.810% | global_loss: 1.560896396636963\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 138 | global_acc: 94.071% | global_loss: 1.5608254671096802\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 139 | global_acc: 93.786% | global_loss: 1.5611425638198853\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 140 | global_acc: 94.048% | global_loss: 1.5597983598709106\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 141 | global_acc: 93.881% | global_loss: 1.560499668121338\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 142 | global_acc: 93.929% | global_loss: 1.5595364570617676\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 143 | global_acc: 94.024% | global_loss: 1.5602973699569702\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 144 | global_acc: 94.095% | global_loss: 1.5601701736450195\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 145 | global_acc: 93.952% | global_loss: 1.5593063831329346\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 146 | global_acc: 93.929% | global_loss: 1.5589607954025269\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 147 | global_acc: 94.214% | global_loss: 1.5586971044540405\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 148 | global_acc: 94.024% | global_loss: 1.557845950126648\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 149 | global_acc: 93.857% | global_loss: 1.5592578649520874\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 150 | global_acc: 94.095% | global_loss: 1.5588757991790771\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 151 | global_acc: 94.000% | global_loss: 1.5586655139923096\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 152 | global_acc: 94.119% | global_loss: 1.5581912994384766\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 153 | global_acc: 94.024% | global_loss: 1.5580233335494995\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 154 | global_acc: 94.190% | global_loss: 1.5575917959213257\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 155 | global_acc: 94.048% | global_loss: 1.5576783418655396\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 156 | global_acc: 93.881% | global_loss: 1.5576764345169067\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 157 | global_acc: 94.214% | global_loss: 1.5571551322937012\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 158 | global_acc: 94.262% | global_loss: 1.5567947626113892\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 159 | global_acc: 94.167% | global_loss: 1.5564390420913696\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 160 | global_acc: 94.190% | global_loss: 1.5567893981933594\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 161 | global_acc: 94.238% | global_loss: 1.5566285848617554\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 162 | global_acc: 94.190% | global_loss: 1.5563387870788574\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 163 | global_acc: 94.214% | global_loss: 1.556214451789856\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 164 | global_acc: 94.286% | global_loss: 1.555620551109314\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 165 | global_acc: 94.262% | global_loss: 1.5553795099258423\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 166 | global_acc: 94.310% | global_loss: 1.5548548698425293\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 167 | global_acc: 94.167% | global_loss: 1.5554465055465698\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 168 | global_acc: 94.310% | global_loss: 1.554548978805542\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 169 | global_acc: 94.286% | global_loss: 1.554308295249939\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 170 | global_acc: 94.167% | global_loss: 1.555173635482788\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 171 | global_acc: 94.310% | global_loss: 1.5535321235656738\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 172 | global_acc: 94.643% | global_loss: 1.5538357496261597\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 173 | global_acc: 94.143% | global_loss: 1.5531504154205322\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 174 | global_acc: 94.357% | global_loss: 1.5522058010101318\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 175 | global_acc: 94.405% | global_loss: 1.5528315305709839\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 176 | global_acc: 94.429% | global_loss: 1.552428126335144\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 177 | global_acc: 94.500% | global_loss: 1.5520039796829224\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 178 | global_acc: 94.524% | global_loss: 1.5523223876953125\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 179 | global_acc: 94.405% | global_loss: 1.551037073135376\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 180 | global_acc: 94.429% | global_loss: 1.550991177558899\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 181 | global_acc: 94.476% | global_loss: 1.551365613937378\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 182 | global_acc: 94.429% | global_loss: 1.5516752004623413\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 183 | global_acc: 94.357% | global_loss: 1.5513970851898193\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 184 | global_acc: 94.619% | global_loss: 1.5506229400634766\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 185 | global_acc: 94.452% | global_loss: 1.5506672859191895\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 186 | global_acc: 94.500% | global_loss: 1.5500473976135254\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 187 | global_acc: 94.548% | global_loss: 1.5500167608261108\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 188 | global_acc: 94.643% | global_loss: 1.549385666847229\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 189 | global_acc: 94.548% | global_loss: 1.5503164529800415\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 190 | global_acc: 94.595% | global_loss: 1.5495405197143555\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 191 | global_acc: 94.381% | global_loss: 1.549408197402954\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 192 | global_acc: 94.595% | global_loss: 1.5498303174972534\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 193 | global_acc: 94.524% | global_loss: 1.5492380857467651\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 194 | global_acc: 94.476% | global_loss: 1.5496470928192139\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 195 | global_acc: 94.476% | global_loss: 1.5497630834579468\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 196 | global_acc: 94.595% | global_loss: 1.5493054389953613\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 197 | global_acc: 94.452% | global_loss: 1.5492740869522095\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 198 | global_acc: 94.643% | global_loss: 1.5485260486602783\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 199 | global_acc: 94.310% | global_loss: 1.5490293502807617\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 200 | global_acc: 94.476% | global_loss: 1.5479631423950195\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 201 | global_acc: 94.595% | global_loss: 1.5479050874710083\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 202 | global_acc: 94.500% | global_loss: 1.5480233430862427\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 203 | global_acc: 94.548% | global_loss: 1.5478309392929077\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 204 | global_acc: 94.762% | global_loss: 1.5475071668624878\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 205 | global_acc: 94.667% | global_loss: 1.546848177909851\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 206 | global_acc: 94.857% | global_loss: 1.5472619533538818\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 207 | global_acc: 94.690% | global_loss: 1.5480692386627197\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 208 | global_acc: 94.548% | global_loss: 1.5479215383529663\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 209 | global_acc: 94.571% | global_loss: 1.547584056854248\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 210 | global_acc: 94.524% | global_loss: 1.5472722053527832\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 211 | global_acc: 94.690% | global_loss: 1.5462716817855835\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 212 | global_acc: 94.571% | global_loss: 1.5473860502243042\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 213 | global_acc: 94.690% | global_loss: 1.5463199615478516\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 214 | global_acc: 94.548% | global_loss: 1.5466936826705933\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 215 | global_acc: 94.571% | global_loss: 1.5464502573013306\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 216 | global_acc: 95.071% | global_loss: 1.5469759702682495\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 217 | global_acc: 94.595% | global_loss: 1.5462225675582886\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 218 | global_acc: 94.714% | global_loss: 1.5457173585891724\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 219 | global_acc: 94.810% | global_loss: 1.545514464378357\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 220 | global_acc: 94.714% | global_loss: 1.545130729675293\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 221 | global_acc: 94.762% | global_loss: 1.5446821451187134\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 222 | global_acc: 94.762% | global_loss: 1.5445504188537598\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 223 | global_acc: 94.786% | global_loss: 1.544996976852417\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 224 | global_acc: 94.714% | global_loss: 1.5442770719528198\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 225 | global_acc: 94.786% | global_loss: 1.5447351932525635\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 226 | global_acc: 94.762% | global_loss: 1.5432437658309937\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 227 | global_acc: 94.857% | global_loss: 1.544510841369629\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 228 | global_acc: 94.690% | global_loss: 1.5439903736114502\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 229 | global_acc: 94.881% | global_loss: 1.5433921813964844\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 230 | global_acc: 94.810% | global_loss: 1.5437465906143188\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 231 | global_acc: 94.714% | global_loss: 1.5438023805618286\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 232 | global_acc: 94.905% | global_loss: 1.5428820848464966\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 233 | global_acc: 94.762% | global_loss: 1.5438297986984253\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 234 | global_acc: 94.714% | global_loss: 1.5433197021484375\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 235 | global_acc: 94.857% | global_loss: 1.5429260730743408\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 236 | global_acc: 94.643% | global_loss: 1.5433298349380493\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 237 | global_acc: 94.619% | global_loss: 1.5435148477554321\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 238 | global_acc: 94.976% | global_loss: 1.5426393747329712\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 239 | global_acc: 94.857% | global_loss: 1.542897343635559\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 240 | global_acc: 94.881% | global_loss: 1.5421249866485596\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 241 | global_acc: 94.738% | global_loss: 1.5430586338043213\n",
      "132/132 [==============================] - 0s 1ms/step\n",
      "comm_round: 242 | global_acc: 94.857% | global_loss: 1.5426117181777954\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 243 | global_acc: 94.929% | global_loss: 1.5432891845703125\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 244 | global_acc: 94.786% | global_loss: 1.5419830083847046\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 245 | global_acc: 94.952% | global_loss: 1.5421299934387207\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 246 | global_acc: 94.905% | global_loss: 1.5422431230545044\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 247 | global_acc: 94.786% | global_loss: 1.5419166088104248\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 248 | global_acc: 94.857% | global_loss: 1.5419672727584839\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 249 | global_acc: 95.000% | global_loss: 1.5414657592773438\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 250 | global_acc: 94.881% | global_loss: 1.54091215133667\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 251 | global_acc: 94.929% | global_loss: 1.5413709878921509\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 252 | global_acc: 94.929% | global_loss: 1.5410270690917969\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 253 | global_acc: 94.857% | global_loss: 1.541365146636963\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 254 | global_acc: 95.000% | global_loss: 1.5408258438110352\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 255 | global_acc: 94.929% | global_loss: 1.5403670072555542\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 256 | global_acc: 94.762% | global_loss: 1.5407944917678833\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 257 | global_acc: 94.905% | global_loss: 1.5404459238052368\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 258 | global_acc: 94.952% | global_loss: 1.5402369499206543\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 259 | global_acc: 94.857% | global_loss: 1.5401599407196045\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 260 | global_acc: 95.024% | global_loss: 1.5399261713027954\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 261 | global_acc: 94.857% | global_loss: 1.5404319763183594\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 262 | global_acc: 95.000% | global_loss: 1.5394238233566284\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 263 | global_acc: 95.000% | global_loss: 1.5392225980758667\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 264 | global_acc: 95.071% | global_loss: 1.539384126663208\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 265 | global_acc: 94.952% | global_loss: 1.5401662588119507\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 266 | global_acc: 95.048% | global_loss: 1.5393344163894653\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 267 | global_acc: 94.857% | global_loss: 1.5404891967773438\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 268 | global_acc: 95.048% | global_loss: 1.53965163230896\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 269 | global_acc: 95.071% | global_loss: 1.539614200592041\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 270 | global_acc: 95.095% | global_loss: 1.5398374795913696\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 271 | global_acc: 95.071% | global_loss: 1.5399388074874878\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 272 | global_acc: 95.071% | global_loss: 1.5392895936965942\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 273 | global_acc: 94.952% | global_loss: 1.5391864776611328\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 274 | global_acc: 95.000% | global_loss: 1.5394357442855835\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 275 | global_acc: 94.976% | global_loss: 1.538788080215454\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 276 | global_acc: 95.095% | global_loss: 1.5392168760299683\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 277 | global_acc: 95.190% | global_loss: 1.5388388633728027\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 278 | global_acc: 95.119% | global_loss: 1.5381147861480713\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 279 | global_acc: 95.238% | global_loss: 1.5386682748794556\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 280 | global_acc: 94.976% | global_loss: 1.5387448072433472\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 281 | global_acc: 95.048% | global_loss: 1.5386766195297241\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 282 | global_acc: 95.167% | global_loss: 1.5385247468948364\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 283 | global_acc: 95.143% | global_loss: 1.5377304553985596\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 284 | global_acc: 95.000% | global_loss: 1.5375818014144897\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 285 | global_acc: 95.024% | global_loss: 1.5382038354873657\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 286 | global_acc: 95.167% | global_loss: 1.5382238626480103\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 287 | global_acc: 95.214% | global_loss: 1.537107229232788\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 288 | global_acc: 95.143% | global_loss: 1.5371642112731934\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 289 | global_acc: 95.000% | global_loss: 1.5376839637756348\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 290 | global_acc: 95.214% | global_loss: 1.5374799966812134\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 291 | global_acc: 94.952% | global_loss: 1.5377941131591797\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 292 | global_acc: 95.119% | global_loss: 1.537221074104309\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 293 | global_acc: 95.000% | global_loss: 1.5377819538116455\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 294 | global_acc: 95.214% | global_loss: 1.5375874042510986\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 295 | global_acc: 95.238% | global_loss: 1.5376209020614624\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 296 | global_acc: 95.143% | global_loss: 1.5374679565429688\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 297 | global_acc: 95.167% | global_loss: 1.537113070487976\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 298 | global_acc: 95.143% | global_loss: 1.5377042293548584\n",
      "132/132 [==============================] - 0s 2ms/step\n",
      "comm_round: 299 | global_acc: 95.214% | global_loss: 1.537489652633667\n"
     ]
    }
   ],
   "source": [
    "# Inicia o Ciclo de Treinamento Global\n",
    "for comm_round in range(comms_round):\n",
    "    \n",
    "    # obtém os pesos do modelo global - servirá como peso inicial para todos os modelos locais\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    # Inicializa a lista para coletar os pesos do modelo local após o dimensionamento\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    # Randomiza os dados dos clientes usando as chaves\n",
    "    all_client_names = list(clients_batched.keys())\n",
    "           \n",
    "    client_names = random.sample(all_client_names, k=10)\n",
    "    # print(client_names, len(client_names))\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    # Descomentar para caso queira verificar as características dos clientes\n",
    "#     if debug: \n",
    "#         # print('all_client_names', all_client_names)\n",
    "#         print('client_names', client_names, len(client_names))\n",
    "                \n",
    "    \n",
    "    # Percorre cada cliente e criar um novo modelo local\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(build_shape, 10)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        # Define o peso do modelo local para o peso do modelo global\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        # Ajustar o modelo local com os dados do cliente\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "        \n",
    "        # Dimensiona os pesos do modelo e adicionar à lista\n",
    "        scaling_factor = 0.1 # weight_scalling_factor(clients_batched, client)\n",
    "        # print('scaling_factor', scaling_factor)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        # Limpa sessão para liberar memória após cada rodada de comunicação\n",
    "        K.clear_session()\n",
    "\n",
    "    # Para obter a média de todo o modelo local, simplesmente pegamos a soma dos pesos escalonados    \n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    # Atualiza o Modelo Global\n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    # Testa o modelo global e imprime as informações de cada round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "        global_acc_list.append(global_acc)\n",
    "        global_loss_list.append(global_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb57427b-94e0-4aaa-b32a-b5653a7ae5c7",
   "metadata": {},
   "source": [
    "## Imprime Gráfico do Desempenho do Modelo Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f3ca207-071b-4a06-a6af-d1770625f720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T14:09:23.593662Z",
     "iopub.status.busy": "2022-10-09T14:09:23.593038Z",
     "iopub.status.idle": "2022-10-09T14:09:24.340612Z",
     "shell.execute_reply": "2022-10-09T14:09:24.340039Z",
     "shell.execute_reply.started": "2022-10-09T14:09:23.593636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist | total comm rounds 300\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(list(range(0,len(global_loss_list))), global_loss_list)\n",
    "plt.subplot(122)\n",
    "plt.plot(list(range(0,len(global_acc_list))), global_acc_list)\n",
    "print('Mnist | total comm rounds', len(global_acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2e23dac-9404-467d-9b75-2c459488162f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T14:09:24.341603Z",
     "iopub.status.busy": "2022-10-09T14:09:24.341442Z",
     "iopub.status.idle": "2022-10-09T14:09:24.354373Z",
     "shell.execute_reply": "2022-10-09T14:09:24.353774Z",
     "shell.execute_reply.started": "2022-10-09T14:09:24.341584Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_df = pd.DataFrame(list(zip(global_acc_list, global_loss_list)), columns =['global_acc_list', 'global_loss_list'])\n",
    "csv_df.to_csv('MNIST_TFF.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbe0cba9-8b90-466c-8bdb-8cac27beda01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-09T14:09:24.355731Z",
     "iopub.status.busy": "2022-10-09T14:09:24.355321Z",
     "iopub.status.idle": "2022-10-09T14:09:24.434943Z",
     "shell.execute_reply": "2022-10-09T14:09:24.433641Z",
     "shell.execute_reply.started": "2022-10-09T14:09:24.355709Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time = 1477.6 s\n"
     ]
    }
   ],
   "source": [
    "timeTotal = time.time() - start_time\n",
    "print(\"Time = %3.1f s\" % timeTotal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
